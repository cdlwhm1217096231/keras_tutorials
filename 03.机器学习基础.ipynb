{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集 测试集 验证集\n",
    "- 在训练集上训练模型，在验证集上评估模型。一旦找到最佳的参数，就在测试数据上最后测试一次\n",
    "- 使用验证集的原因：开发模型时，总要调节模型配置，比如超参数的设置(层数 隐藏层节点数) 模型参数的设置(网络的权重)，这个\n",
    "调节过程需要使用模型在验证数据上的性能作为反馈信号。\n",
    "- 将数据划分为训练集 测试集 验证集的高级方法:\n",
    "    - 1.简单留出验证\n",
    "        - 留出一定比例的数据作为测试集，在剩余的数据上训练模型，然后在测试集上评估模型，为了防止信息泄漏，不能基于测试集来调节模型，所以要保留一个验证集。\n",
    "   如果可用的数据很少，那么可能验证集和测试集包含的样本就太少，从而无法在统计学上代表数据。\n",
    "这个问题很容易发现：如果在划分数据前进行不同的随机打乱，最终得到的模型性能差别很大，那么就存在这个问题。\n",
    "    - 2.K折验证\n",
    "        - K 折验证（ K-fold validation）将数据划分为大小相同的 K 个分区。 对于每个分区 i，在剩余的 K-1 个分区上训练模型，然后在分区 i 上评估模型。最终分数等于 K 个分数的平均值。对\n",
    "于不同的训练集 - 测试集划分，如果模型性能的变化很大，那么这种方法很有用。与留出验证一样，这种方法也需要独立的验证集进行模型校正。\n",
    "    - 3. 带有打乱数据的重复 K 折验证\n",
    "        - 如果可用的数据相对较少，而你又需要尽可能精确地评估模型，那么可以选择带有打乱数据的重复 K 折验证（ iterated K-fold validation with shuffling）。我发现这种方法在 Kaggle 竞赛中特别有用。具体做法是多次使用 K 折验证，在每次将数据划分为 K 个分区之前都先将数据打乱。最终分数是每次 K 折验证分数的平均值。注意，这种方法一共要训练和评估 P× K 个模型（ P是重复次数），计算代价很大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5db0b4336895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 训练集上训练模型，验证集上评估模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mvalidation_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_model' is not defined"
     ]
    }
   ],
   "source": [
    "############ 留出验证法 ######################\n",
    "data = np.arange(10)\n",
    "import numpy as np\n",
    "num_validation_samples = 10000  # 验证集大小\n",
    "np.random.shuffle(data)  # 随机打乱数据\n",
    "## 定义验证集 \n",
    "validation_data = data[:num_validation_samples]\n",
    "# 定义训练集\n",
    "training_data = data[:]\n",
    "# 训练集上训练模型，验证集上评估模型\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "'''调整超参数 重新训练再调节 训练 得到最佳参数'''\n",
    "# 确定超参数后，在原始数据上测试模型\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data,\n",
    "validation_data]))\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K折交叉验证\n",
    "k = 4\n",
    "num_validation_samples = len(data) // k\n",
    "np.random.shuffle(data)\n",
    "validation_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    # 验证集数据分区\n",
    "    validation_data = data[num_validation_samples * i:num_validation_samples*(i+1)]\n",
    "    # 剩下数据作为训练集\n",
    "    training_data = data[:num_validation_samples*i] + data[num_validation_samples*(i+1):]\n",
    "    \n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "    \n",
    "validation_score = np.average(validation_scores)\n",
    "\n",
    "# 在所有非测试数据上训练最终模型\n",
    "model = get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "- 1.向量化\n",
    "神经网络的所有输入和目标都必须是浮点数张量（在特定情况下可以是整数张量）。无论处理什么数据（声音、图像还是文本），都必须首先将其转换为张量，这一步叫作数据向量化\n",
    "- 2.值标准化\n",
    "    - 输入数据应该具有以下特征：\n",
    "        - 取值较小：大部分值都应该在 0~1 范围内\n",
    "        - 同质性（ homogenous）：所有特征的取值都应该在大致相同的范围内\n",
    "        - 将每个特征分别标准化，使其平均值为 0  将每个特征分别标准化，使其标准差为 1\n",
    "        - numpy实现\n",
    "            ```python\n",
    "            x -= x.mean(axis=0)\n",
    "            x /= x.std(axis=0)\n",
    "            ```\n",
    "- 3.缺失值处理\n",
    "    - 一般来说，对于神经网络，将缺失值设置为0是安全的，只要0不是一个有意义的值。网络能够从数据中学到0意味着缺失数据，并且会忽略这个值\n",
    "    - 注意，如果测试数据中可能有缺失值，而网络是在没有缺失值的数据上训练的，那么网络不可能学会忽略缺失值。在这种情况下，你应该人为生成一些有缺失项的训练样本：多次复制一些训练样本，然后删除测试数据中可能缺失的某些特征\n",
    "           \n",
    "### 特征工程\n",
    "- 特征工程（ feature engineering）是指将数据输入模型之前，利用你自己关于数据和机器学习算法（这里指神经网络）的知识对数据进行硬编码的变换（不是模型学到的），以改善模型的效果。多数情况下，一个机器学习模型无法从完全任意的数据中进行学习，呈现给模型的数据应该便于模型进行学习\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过拟合和欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])  # 键值颠倒，将整数索引映射为单词\n",
    "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]]) # 将评论解码，将索引减去3,由于0,1,2是填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_squences(squences, dimension=10000):\n",
    "    results = np.zeros((len(squences), dimension))\n",
    "    for i, sequence in enumerate(squences):\n",
    "        results[i, sequence] = 1.\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将训练和测试数据向量化，采用one-hot编码\n",
    "\n",
    "x_train = vectorize_squences(train_data)\n",
    "x_test = vectorize_squences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 标签向量化\n",
    "y_train = np.asarray((train_labels).astype('float32'))\n",
    "y_test = np.asarray((test_labels).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#模型定义\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cdl/.conda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# 编译模型\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 配置优化器\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 留出验证集---------将原始训练数据留出10000个样本作为验证集合\n",
    "\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 4s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6933 - val_acc: 0.4948\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6933 - val_acc: 0.4948\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4948\n"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=512,\n",
    "validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'acc', 'loss', 'val_acc'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history  # model.fit()方法返回一个history对象，调用此对象下的history方法，可以查看训练中的所有数据\n",
    "history_dict.keys()  # 对应训练和测试中的监控指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEWCAYAAAC5XZqEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOQs+xhhjYu7/ARuy0h9Fgx0DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1bba5f4b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 奥卡姆剃刀（ Occam’s razor）原理：如果一件事情有两种解释，那么最可能正确的解释就是最简单的那个，即假设更少的那个\n",
    "\n",
    "### 添加正则化\n",
    "- L1 正则化（ L1 regularization）：添加的成本与权重系数的绝对值［权重的L1范数（ norm）］成正比。\n",
    "- L2 正则化（ L2 regularization）：添加的成本与权重系数的平方（权重的L2范数）成正比。神经网络的 L2 正则化也叫权重衰减（weight decay）。不要被不同的名称搞混，权重衰减与 L2 正则化在数学上是完全相同的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cdl/.conda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# 添加l2正则化\n",
    "from keras import regularizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# l2(0.001)的意思是该层权重矩阵的每个系数都会使网络总损失增加 0.001 * weight_coefficient_value。注意，由于这个惩罚项只在训练时添加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 添加l1正则化\n",
    "\n",
    "from keras import regularizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.001),activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.001),activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 同时添加l1  l2正则化\n",
    "\n",
    "from keras import regularizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 添加 dropout 正则化\n",
    "# 在 Keras 中，你可以通过 Dropout 层向网络中引入 dropout， dropout 将被应用于前面一层的输出。\n",
    "from keras import regularizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 防止神经网络过拟合的常用方法：\n",
    "- 获取更多的训练数据\n",
    "- 减小网络容量\n",
    "- 添加权重正则化\n",
    "- 添加 dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习的通用工作流程：\n",
    "- 定义问题，收集数据集\n",
    "- 选择衡量成功的指标\n",
    "    - 对于平衡分类问题（每个类别的可能性相同），精度和接收者操作特征曲线下面积（ area under the receiver operating characteristic curve， ROC AUC）是常用的指标。\n",
    "    - 对于类别不平衡的问题，你可以使用准确率和召回率。\n",
    "    - 对于排序问题或多标签分类，你可以使用平均准确率均值（ mean average precision）。\n",
    "- 确定评估方法\n",
    "    - 留出验证集。数据量很大时可以采用这种方法。\n",
    "    - K 折交叉验证。如果留出验证的样本量太少，无法保证可靠性，那么应该选择这种方法。\n",
    "    - 重复的 K 折验证。如果可用的数据很少，同时模型评估又需要非常准确，那么应该使用这种方法\n",
    "- 准备数据\n",
    "    - 如前所述，应该将数据格式化为张量。\n",
    "    - 这些张量的取值通常应该缩放为较小的值，比如在 [-1, 1] 区间或 [0, 1] 区间。\n",
    "    - 如果不同的特征具有不同的取值范围（异质数据），那么应该做数据标准化。\n",
    "    - 你可能需要做特征工程，尤其是对于小数据问题。\n",
    "- 开发第一个比基准更好的模型，即一个具有统计功效的模型。\n",
    "    - 需要选择三个关键参数来构建第一个工作模型\n",
    "        - 最后一层的激活。它对网络输出进行有效的限制。\n",
    "        - 损失函数。它应该匹配你要解决的问题的类型\n",
    "        - 优化配置。你要使用哪种优化器？学习率是多少？大多数情况下，使用rmsprop及其默认的学习率是稳妥的。\n",
    "        <hr>\n",
    "        | 问题类型   |    最后一层激活      | 损失函数 |\n",
    "\n",
    "        | 二分类问题 | sigmoid            | binary_crossentropy |\n",
    "\n",
    "        | 多分类、单标签问题 | softmax      | categorical_crossentropy |\n",
    "\n",
    "        | 多分类、多标签问题 | sigmoid      | binary_crossentropy |\n",
    "\n",
    "        | 回归到任意值      | 无            | mse |\n",
    "\n",
    "        | 回归到 0~1 范围内的值 | sigmoid   | mse或binary_crossentropy |\n",
    "- 扩大模型规模：开发过拟合的模型\n",
    "    - (1) 添加更多的层。\n",
    "    - (2) 让每一层变得更大。\n",
    "    - (3) 训练更多的轮次。\n",
    "    - 要始终监控训练损失和验证损失，以及你所关心的指标的训练值和验证值。如果你发现模型在验证数据上的性能开始下降，那么就出现了过拟合。\n",
    "- 模型正则化与调节超参数\n",
    "    - 添加 dropout。\n",
    "    - 尝试不同的架构：增加或减少层数。\n",
    "    - 添加 L1 和 / 或 L2 正则化。\n",
    "    - 尝试不同的超参数（比如每层的单元个数或优化器的学习率），以找到最佳配置。\n",
    "    - 反复做特征工程：添加新特征或删除没有信息量的特征。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
